import requests
from bs4 import BeautifulSoup
import pandas as pd
from random import randint
from time import sleep


class Scraper:
    """
    Class to scrape the sneakers from Sivasdescalzo.com
    """
    sneakers_list = []
    product_links = []

    def set_product_links(self):
        """
        Function that iterates through the shoe pages, obtaining a file in lxml format.
        In this file it executes a search by href obtaining the links of each one of the products.
        """
        for page in range(0, 10):
            r = requests.get(f'https://www.sivasdescalzo.com/es/calzado?p={page}')

            soup = BeautifulSoup(r.content, 'lxml')
            self.product_list = soup.find_all('div', class_='product-item-info product-card')

            for item in self.product_list:
                for link in item.find_all('a', href=True):
                    self.product_links.append(link['href'])
            sleep(randint(1, 8))

    def get_product_links(self):
        """
        Product links getter.

        :return: a list with the product links.
        """
        return self.product_links

    def set_product_attributes(self):
        """
        Function that iterates through the different products obtaining an lmxl file,
        where it performs a search and extracts its different attributes:
        [name, model, price, discount, description]
        """
        for link in self.product_links:
            r = requests.get(link)
            soup = BeautifulSoup(r.content, 'lxml')
            name = soup.find('span', class_='product-data__brand-name').text
            model = soup.find('span', class_='product-data__model').text
            price = soup.find('span', class_='price').text.replace('\xa0', '')
            try:
                discount = soup.find('span', class_='price-discount-percent').text
            except:
                discount = '0 %'
            description = soup.find('div', class_='product-data__short-desc').text.replace('Más información',
                                                                                           ' ').rstrip()
            sneakers = {
                'name': name,
                'model': model,
                'price': price,
                'discount': discount,
                'description': description
            }
            print(sneakers)
            self.sneakers_list.append(sneakers)
            sleep(randint(1, 5))

    def get_attributes(self):
        """
        Product attributes getter.

        :return: a list with the product attributes.
        """
        return self.product_list

    def transform_to_csv(self):
        """
        Function that transforms data to pandas DataFrame object and
        comma separated value.

        :return: a pandas DataFrame object.
        """
        df = pd.DataFrame(self.sneakers_list)
        df.to_csv('../data/sneakers.csv', sep=',',
                  encoding='utf-8', header=['id', 'name', 'model',
                                            'price', 'discount', 'description'])
        return df
    
    def get_product_info(self):
        # Creamos una lista en la que introducir la info útil que obtengamos
        sneakers_list = []

        # Recorremos las páginas de la web para extraer información de todos los zapatos
        for i in range(1,20):
            r = requests.get(f'https://www.sivasdescalzo.com/es/calzado?p={i}')
            soup = BeautifulSoup(r.content, 'lxml')

            # Creamos lista de los productos
            product_list = soup.find_all('div', class_ = 'product-card__info product details product-item-details')

            # Extraemos la info que nos interesa de cada producto
            for product in product_list:
                name = product.find('a', class_ = 'set-product-storage').text
                model = product.find('a', class_ = 'product-item-link set-product-storage').text
                # price_list contiene el precio actual, el precio antiguo y el descuento
                # Hay que hacer un split para separar cada una de las cosas e introducirlo en nuestro dataset
                price_list = product.find('span', class_ = 'price').text.replace('\xa0€', '')

                # Almacenamos la info en un diccionario
                sneaker = {
                    'name': name,
                    'model': model,
                    'price (€)': price
                    }
                sneakers_list.append(sneaker)
            
            # Esperamos un tiempo para realizar la siguiente búsqueda y evitar bloqueos
            sleep(randint(1, 4))
        return self.sneakers_list


if __name__ == '__main__':
    scrape = Scraper()
#    scrape.set_product_links()
    scrape.get_product_info()
#    scrape.transform_to_csv()
